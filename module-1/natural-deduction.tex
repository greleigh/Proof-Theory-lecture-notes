% --------------------------------------
\chapter{Preliminaries}
% --------------------------------------

Set-theoretic notation. Let \( X \) be a set.
\begin{itemize}
	\item \( \Pow X \) is the power set of \( X \).
	\item \( X^{<ω} \) denotes the set of finite sequences in \( X \), namely the set of \( ( x_1 , …, x_n ) \) for \( n < ω \) and \( x_i ∈ X \).
	\item The cardinality of \( X \) is denoted \( \card X \); except where stated otherwise, this will invariably be either a natural number (\( X \) is finite) or \( ω \) (meaning \( X \) is countably infinite).
\end{itemize}


%I begin with defining the syntactic notions of formula, etc.

% ------------------------
\section{The language of logic}
% ------------------------

The \emph{logical symbols of propositional logic} are
\[ 
	∧ \quad  ∨ \quad  → \quad ⊥ 
\]
collectively called the \emph{(propositional) connectives}.
To these one adds a collection \( \Lang P \) of \emph{propositional variables} to obtain a \emph{propositional language}.

The \emph{logical symbols of (first-order) predicate logic} extends the propositional symbols by
\begin{itemize}
%	\item Connectives: \( ∧ \), \( ∨ \), \( → \) and \( ⊥ \).
	\item Quantifiers: \( ∀ \) and \( ∃ \).
	\item Bound variables: \( v_0 \), \( v_1 \), ….
	\item Free variables: \( a_0 \), \( a_1 \), ….
\end{itemize}
%
%
\begin{definition}
A \emph{first-order language} extends the logical symbols by two sets of \emph{non-logical} symbols:
\begin{itemize}
	\item a set \( \Lang F \) of \emph{function symbols};
	\item a set \( \Lang P \) of \emph{predicates};
	\item a function \( \arity \colon \Lang F ∪ \Lang P → ℕ \) assigning each symbol a natural number called the \emph{arity}.
\end{itemize}
The \emph{propositional} fragment of a first-order language arises by dropping all function symbols and all predicates of non-zero arity.
\end{definition}
%
A function symbol \( f ∈ \Lang F \) with arity \( \arity (f) = 0 \) is called a \emph{constant}; 
a predicate \( P ∈ \Lang P \) with arity \( 0 \) is a \emph{propositional variable}.
A symbol is \emph{nullary}, \emph{unary}, …, \emph{$n$-ary} if it has arity \( 0 \), \( 1 \), …, \( n \), etc..


Terms and formulas are defined as expected but should adhere to the free/bound variable distinction.
%\begin{itemize}
%%	\item Terms never contain bound variables.
%	\item Quantifiers only ever \emph{bind} bound variables.
%\end{itemize}
%
%
\begin{definition}[Term]
	The \emph{terms} are defined inductively as follows:
	\begin{enumerate}
		\item Every free variable is a term
		\item Given terms \( t_1 \), …, \( t_n \) and an \( n \)-ary function symbol \( f \), \( f t_1 ⋯ t_n \) is a term.
	\end{enumerate}
	Adding bound variables into the mix creates the class of syntactic objects I call \emph{pre-terms}:
	\begin{enumerate}
		\item Every variable (free or bound) is a pre-term.
		\item Given pre-terms \( t_1 \), …, \( t_n \) and an \( n \)-ary function symbol \( f \), \( f t_1 ⋯ t_n \) is a pre-term.
	\end{enumerate}
	The variables occurring in a pre-term \( t \) are called the \emph{active} (of the pre-term).
	In other words, a term is a pre-term in which only free variables are active.
	A (pre-)term with no active variables is \emph{closed}.
\end{definition}
%
With terms come formulas.

\begin{definition}[Atomic formula; prime formula]
	An expression \( P t_1 ⋯ t_n \) where \( P \) is an \( n \)-ary predicate and \( t_1 \), …, \( t_n \) are terms is called an \emph{atomic formula}.
	The atomic formulas together with the symbol \( ⊥ \) are, collectively, the \emph{prime} formulas.
\end{definition}
%
%
\begin{definition}[Pre-formula]
	The \emph{pre-formulas}, and their active variables, are generated by the following clauses.
	\begin{enumerate}
		\item Given pre-terms \( t_1 \), …, \( t_n \) and \( n \)-ary predicate \( P \), \( P t_1 ⋯ t_n \) is a pre-formula. A variable is \emph{active} in \( P t_1 ⋯ t_n \) iff it is active in (at least) one of the \( t_i \).
		\item \( ⊥ \) is a pre-formula with no active variables.
		\item If \( F \) and \( G \) are pre-formulas, then so is \( F → G \), \( F ∧ G \) and \( F ∨ G \). The active variables in each case is the union of active variables of each of \( F \) and \( G \).
		\item If \( F \) is a pre-formula and \( x \) a bound variable, then \( ∀x F \) and \( ∃ x F \) are pre-formulas. The active variables of \( ∀ x F \) and \( ∃ x F \) are the active variables of \( F \) minus   the variable \( x \).
	\end{enumerate}
\end{definition}
%
\begin{definition}[Formula]
	A \emph{formula} is a pre-formula for which only free variables are active.
	A formula with \emph{no} active variables is called \emph{closed} or a \emph{sentence}.
\end{definition}

It is helpful in many cases to associate a numerical measure of \emph{complexity} to (pre-)formulas.
There are many choices.
I take the following.

\begin{definition}[Formula complexity]
	The \emph{complexity} of a pre-formula \( F \) is denoted \( \rk F \) and determined by recursion on its generation:
	\begin{itemize}
		\item \( \rk F = 0 \) if \( F \) is prime.
		\item \( \rk{ F ∧ G } = \rk{ F ∨ G } = \rk{ F → G } = \maxof{ \rk F, \rk G} + 1 \).
		\item \( \rk{ ∀x F } = \rk{ ∃x F } = \rk{ F } + 1 \).
	\end{itemize}
\end{definition}


%
\begin{definition}[Substitution]
%	Let \( F \) be a pre-formula and \( \vec t = t_0 , …, t_n \) a finite sequence of pre-terms.
%
	Let \( F \) be a pre-formula, \( a \) a free variable and \( t \) a pre-term.
	I write \( F[t/a] \) for the pre-formula that results by substituting \( t \) for \( a \) in \( F \).
	This is defined recursively over terms and formulas:
	\begin{align*}
		a_j [ t/a_i ] &= 
		\begin{cases}
			t, &\text{if \( i = j \),}
			\\
			a_j, &\text{otherwise.}
		\end{cases}
		\\
		v_j [ t/a_i ] &= v_j.
		\\
		( S t_1 ⋯ t_n ) [ t/a_i ] &= S ( t_1 [ t/a_i ] ) ⋯ ( t_n [ t/a_i ] ) \; \text{for \( S ∈ \Lang F ∪ \Lang P \).}
%		\\
%		( P t_1 ⋯ t_n ) [ t/a_i ] &= P ( t_1 [ t/a_i ] ) ⋯ ( t_n [ t/a_i ] )
		\\
		⊥ [ t/a_i ] &= ⊥.
		\\
		( F * G ) [ t/a_i ] &= F [ t/a_i ] \,*\, G [ t/a_i ]  \; \text{for \( * ∈ \setof{∧ , ∨,→} \).}
		\\
		( Q x F ) [ t/a_i ] &= Qx \;  F [ t/a_i ] \; \text{for \( Q ∈ \setof{ ∀ , ∃ } \).}
	\end{align*}
	Simultaneously substituting a sequence of terms \( \vec s = s_0 , …, s_n \) for variables \( \vec c = c_{0} , …, c_{n} \) (where \( c_i ≠ c_{j} \) for all \( i<j ≤ n \)) is defined in the expected way and denoted \( F[ \vec s/\vec c] \) or \( F[ s_0/c_{0}, …, s_n/c_n ] \).
\end{definition}

\begin{lemma}
	If \( F \) is a formula and \( t \) a term,  \( F[t/a] \) is a formula.
\end{lemma}

\begin{convention}[Meta-variables]\label{conv-metavar}
	Henceforth, I adopt the following naming conventions except where explicitly stated otherwise.
	\begin{itemize}
		\item lower case roman letters:
		\begin{itemize}
		\item \( x \), \( y \), \( z \) (often with subscript, \( x_0 \), \( x_1 \), etc.\@) denote \emph{bound} variables,
		\item \( a \), \( b \), etc.\@ denote \emph{free} variables,
		\item \( r \), \( s \) and \( t \) range over terms (not pre-terms);
		\end{itemize}
		\item upper case Roman letters \( F \), \( G \), \( A \), \( B \), etc.\@ denote pre-formulas;
		\item upper case Greek letters \( Γ \), \( Δ \), etc.\@ denote finite sets of formulas.
	\end{itemize}
\end{convention}

\begin{convention}[Denoting substitution]\label{conv-subst}
	I will often introduce a formula along with a free variable, in the form of \( F(a) \). 
	This notation indicates that \( a \) is to be the focus of subsequent substitutions, whereby I write \( F(t) \) in place \( F[t/a] \).
	
	Sometimes the free variable \( a \) is not mentioned explicitly.
	I may introduce a (pre-)formula as \( F(x) \), subsequently writing \( F(t) \).
	In this context, \( F(x) \) formally represents \( G[x/a] \) for an appropriate choice of \( a \) (and \( G \)), whereby \( F(t) \) means \( G[t/a] \).
\end{convention}


Finally, I introduce three formulaic abbreviations:
\begin{itemize}
	\item \( ⊤ \) abbreviates the formula \( ⊥ → ⊥ \).
	\item \( ¬ F \) is shorthand for \( F → ⊥ \).
	\item \( F ↔ G \) abbreviates \( ( F → G ) ∧ ( G → F ) \).
\end{itemize}


% --------------------------------------
\section{Orders and trees}
% --------------------------------------

The various derivation calculi I present are all based on the mathematical notion of a tree.
%I will start with recapping the mathematical definition of a tree.
Recall that a relation \( ≤ \) on a set \( X \) is a \emph{partial order} iff it is:
\begin{enumerate}
	\item \emph{Reflexive:} \( x ≤ x \) for all \( x ∈ X \),
	\item \emph{Transitive:} if \( x ≤ y \) and \( y ≤ z \), then \( x ≤ z \),
	\item \emph{Anti-symmetric:} if \( x ≤ y \) and \( y ≤ x \) then \( x = y \),
\end{enumerate}
%
and is a \emph{linear order} if, in addition, it is
\begin{enumerate}[resume]
	\item \emph{Linear:} for all \( x,y ∈ X \), either \( x ≤ y \) or \( y ≤ x \).
\end{enumerate}
%
Given a partial order \( ≤ \), I use \( < \) to denote the derived \emph{strict} suborder, defined by \( x < y \) iff \( x ≤ y \) and \( x ≠ y \).

A \emph{tree} is a non-empty set \( T \), elements of which are called \emph{vertices}, equipped with a partial order \( ≤ \) satisfying:
\begin{enumerate}
	\item There exists a \( ≤ \)-minimal vertex \( * ∈ T \), called the \emph{root}. Minimality of \( * \) means that \( * ≤ v \) for all \( v ∈ T \).
	\item For every \( v ∈ T \), the set \( \setof{u ∈ T}[u ≤ v] \) of \emph{predecessors} of \( u \) is finite and linearly ordered by \( ≤ \).
\end{enumerate}

The following are straightforward consequences of the definition. Let \( ( T, ≤ ) \) be a tree and \( v \) a vertex.

\begin{lemma}
	Every non-root vertex has a \( ≤ \)-maximal predecessor.
	I.e., for every \( v ≠ * \) there is a unique \( v_* < v \) such that \( u < v \) iff \( u ≤ v_* \).
\end{lemma}

The vertex \( v_* \) in the above lemma is called the \emph{immediate predecessor} of \( v \), and I say that \( v \) is a \emph{child} of \( v_* \).
%A \emph{child} of \( v \) is any vertex \( u > v \) such that \( v = u_* \).
The set of \emph{children} of \( v \) is denoted
\[
	\Child_T(v) = \setof{u ∈ T}[v = u_*] .
\]
A \emph{leaf} is a vertex with no children.
If the tree is clear from context I will omit its mention, writing, for instance, \( \Child (v) \) for \( \Child_T(v) \).

For the most part, I will only treat finite trees.
In Module~\ref{module-3}, I present a sequent calculus whose derivations are, in general, infinitely branching trees, i.e., the set \( \Child(v) \) can be infinite for some \( v \).
Such trees will still maintain another notion of finiteness in the sense of not containing any infinite branches, called \emph{well-founded} trees.
%
\begin{definition}[Well-founded tree]
%	Let \( ≤ \) be a partial order on a set \( T \).
%	I call \( ≤ \) \emph{well-founded} if there is no infinite for every sequence
	Let \( (T , ≤ ) \) be a tree.
	A \emph{path} through \( T \) is a finite sequence \( (v_i)_{i ≤ k} \) such that \( v_{i+1} ∈ \Child (v_i) \) for all \( i < k \).
	An infinite sequence \( (v_i)_{i ∈ ℕ } \) for which the prefix \( ( v_i)_{i ≤ k} \) is a path for every \( k \) is called a \emph{branch}.
	
	A tree is \emph{well-founded} iff it has no branches.
\end{definition}

% --------------------------------------
\chapter{Natural deduction}
% --------------------------------------

%Although I recap the main
I assume the reader is familiar with some deduction calculus/proof system for classical predicate logic.
The precise calculus is not so important, so long as you understand the concept of a derivation system and the kind of object that constitutes a formal proof.

In these notes, I utilise two such calculi: \emph{natural deduction} and \emph{sequent calculi}.
The latter will be introduced and covered in much detail, beginning in the next chapter.
Natural deduction will also be given a formal definition.
But I will gloss over some aspects that would be considered important in a first introduction, assuming that you either have seen the material before (for instance, in~\citetalias{LogThe}) or can quickly relate the natural deduction calculus to the formal calculus you are most familiar with.

The various notions of \emph{(formal) deduction/proof}, including those addressed in this work, have a common underlying structure.
Namely, they are trees in which vertices are labelled by a certain kind of syntactic object --- formulas in the case of natural deduction --- and the relation between the label of a vertex and the label of its children corresponds to one of number of specified \emph{rules of inference}.

An \emph{inference over \( X \)} is a pair \( ( P , c ) ∈ X^{<ω} × X \), where \( P \) is a finite sequence of objects --- the \emph{premises} --- and \( c \) is a single deduction object, called the \emph{conclusion}.
For \( P = ( P_1 , …, P_n ) \), I visualise the inference \( ( P , C ) \) as a rule
\[
%\begin{prooftree}
%	\hypo{ \Setof{ p }[ p ∈ P] }
%	\infer1[$(P,c)$]{c}
%\end{prooftree}
%\qquad\text{or, if }P = \setof{p_1, …, p_n},\quad
\begin{prooftree}
	\hypo{ P_1 }
	\hypod \hypo{ P_n }
	\infer3{C}
\end{prooftree}
\]
which \emph{derives} the conclusion \( C \) from premises \( P_1 \), …, \( P_n \).

In natural deduction the set of formulas play the role of \( X \) and inferences relate finitely many premises (indeed, at most three) to a conclusion formula.
In short, an inference in natural deduction is a pair \( ( Γ , F ) \) where \( Γ \) is a finite sequence of formulas.
Examples are
\[
  \begin{prooftree}
  	\hypo{F}
  	\infer1{F ∨ G}
  \end{prooftree}
	\qquad
  \begin{prooftree}
  	\hypo{F}
  	\hypo{G}
  	\infer2{F ∧ G}
  \end{prooftree}
	\qquad
  \begin{prooftree}
  	\hypo{ F →  G }
  	\hypo{F}
  	\infer2{G}
  \end{prooftree}
\]
%The third inference above is the form of the elimination rule for disjunction.

Abstractly then, an derivation calculus comprises two pieces of information:
\begin{itemize}
	\item A set \( \Coll O \) of deduction \emph{objects};
	\item A set \( \Coll I ⊆ \Coll O^{<ω} × \Coll O \) of \emph{inferences} or \emph{rules}.
\end{itemize}

\begin{definition}[Derivation]
	A \emph{derivation} in the calculus \( (\Coll O , \Coll I ) \) is a tree \( (T, ≤) \) together with a map \( o \colon T → \Coll O \) assigning a deduction object to each vertex such that every vertex together with its children is an inference, i.e., for all \( v \) there exists an enumeration \( v_1 , …, v_n \) of \( v \)'s children such that
	\[
		\bigl( \, ( o(v_1) , …, o(v_n) ) , o(v) \, \bigr) ∈ \Coll I \!.
	\]
	The deduction object labelling the root of \( T \) is called the \emph{conclusion} of the derivation.
\end{definition}

Observe that every vertex of a derivation must be the conclusion of an inference. 
In particular, objects labelling \emph{leaves} must be derivable without premises.
In some calculi zero-premise inferences correspond to \emph{axioms} but in natural deduction they represent \emph{assumptions} which other rule can ‘mark’ as \emph{discharged} (or left \emph{undischarged}) by certain inferences.
Rules that ‘discharge’ assumptions are drawn as
\[
%  \begin{prooftree}
%	\hypo{[A]}
%	\ellipsis{}{B}
%	\infer1{C}
%\end{prooftree}
%\qquad \text{or}\qquad
  \begin{prooftree}
  	\hypo{b_0}
	\hypo{[a_1]}
	\ellipsis{}{b_1}
	\hypod
	\hypo{[a_n]}
	\ellipsis{}{b_n}
	\infer4{c}
\end{prooftree}
\]
illustrating that there is an inference \( \smash{\bigl( ( b_0,…,b_n) , c \bigr)} \) deriving \( c \) from premises \( b_0 \), …, \( b_n \) and that in the subtree above \( b_i \) (\( i>0 \)) occurrences of an \emph{assumption} \( a_i \) can be considered discharged.

Examples of assumption-discharging inferences in natural deduction are the introduction rule for implication and elimination rule for disjunction:
\[
\begin{prooftree}
	\hypo{[F]}
	\ellipsis{}{G}
	\infer1{ F → G }
\end{prooftree}
\qquad \qquad
\begin{prooftree}
  	\hypo{F ∨ G}
	\hypo{[F]}
	\ellipsis{}{H}
	\hypod
	\hypo{[G]}
	\ellipsis{}{H}
	\infer4{H}
\end{prooftree}
\]
%Labelling or recording assumptions as discharged does not need to be part of the deduction system, per se, but determines

A final quirk of natural deduction is that some inferences are only applicable if the subderivation above them fulfils some condition.
This is the case for two of the quantifier inferences:
\[
	\begin{prooftree}[center=false]
		\hypo{ F(a) }
		\infer1{ ∀x F(x) }
	\end{prooftree}
	\qquad
	\begin{prooftree}[center=false]
		\hypo{ ∃x F(x) }
		\hypo{ [ F(a) ] }
		\ellipsis{}{ H }
		\infer2{ H }
	\end{prooftree}
\]
which are associated a condition --- the \emph{eigenvariable} condition --- that restrict their application to contexts in which the distinguished free variable \( a \) does not occur in any \emph{undischarged} assumptions above the application of this rule.

It is these additional constraints on natural ‘deductions’ that explain the use of the term ‘derivation’ above rather than ‘deduction’ or ‘proof’.
Formally, some proof calculi are also equipped with a ‘correctness condition’ that identifies when a \emph{derivation} is \emph{well-formed} and can be considered a \emph{deduction} or a \emph{proof} in the calculus.

Before turning our full attention to natural deduction, I want the clarify the distinction between \emph{inference} and \emph{rule}.
Above, I used the two terms almost interchangeably, as a specification of the premises and conclusions that can be used in derivations of a particular calculus.
But when defining a system like natural deduction, we do not actually write down all the inferences. Rather, we present a set of schema or \emph{rules} that generate the \emph{inferences}.
%Usually, it is the rules that we give names to
The \emph{rule} called \( \conjI \), or \emph{\( ∧ \)-introduction}, is the set of all inferences
\[
  \begin{prooftree}
  	\hypo{F}
  	\hypo{G}
  	\infer2[$\conjI$]{F∧G}
  \end{prooftree}
\]
where $F$ and $G$ range over formulas.
%For derivations, I identify a


Thus, to fully specify a deduction calculus a third bit of information is sometimes (though not always) needed:

\begin{definition}[Calculus; deduction]
	A \emph{calculus} is a triple \( \Logic C = ( \Coll O , \Coll R , \Coll C ) \) where
	\begin{itemize}
		\item \( \Coll O \) is a set of \emph{deduction objects};
		\item \( \Coll R  \) is a set of \emph{rules}, where a rule is a set of inference over \( \Coll O \); % generating the inferences \( \Coll I = \bigcup _{\Rule r ∈ \Coll R} \Rule r \);
		\item \( \Coll C \) is a \emph{correctness condition} specifying which derivations in \( \Coll O \) and \( \Coll R \) are \emph{deductions}.
	\end{itemize}
\end{definition}
%
I could, of course, have incorporated the correctness condition into the definition of derivation.
Indeed, this is the approach that most texts in formal logic take.
I write ‘formal logic’ and not ‘proof theory’ because the majority of textbooks in proof theory including the standard references~\citep{Negri_von_Plato,Troelstra_Schwichtenberg_2000,Schu1950,Pohlers_1989}
are, understandably, more careful with the definition of proof.
%Nevertheless, the reader will have difficulty finding a text on proof theory that defines a calculus quite in the way I have.
%Either the text st

The purpose of drawing attention to the correctness condition is to emphasise that \emph{proofs} (in natural deduction) are not completely straightforward and, ultimately, isolating a deduction calculus with only trivial correctness conditions (finiteness say) will be extremely helpful.

Recall that only the deduction objects and rules are required for the definition of \emph{derivation}
I deliberately refrain from giving a formal definition of what constitutes a correctness condition as it is not particularly important.

% --------------------------------------
\section{Intuitionistic logic}
% --------------------------------------


%A \emph{deduction} is a finite tree of formulas such that the formula labelling a vertex is related to the formula(s) labelling the children
%The rules of intuitionistic natural deduction are
In natural deduction, each logical connective and quantifier is associated two kinds of rule: an \emph{introduction} rule, how to \emph{infer} a formula using the connective, and an \emph{elimination} rule, what can \emph{inferred} from the connective.
%In some cases, either category is further split into cases (such as \( \conjE \) below).

I present each rule in turn. Unless otherwise stated, in all cases symbols $F$, $G$, $a$, $t$, etc.\@ act as meta-variables ranging over all objects of the appropriate type, rather than denoting specific instances.
\begin{figure}
\centering \ebproofset{center=false}
\begin{gather*}
\begin{prooftree}
	\axiom[\assumpo]{F}
\end{prooftree}
\qquad
\begin{prooftree}
	\axiom[\assumpd]{F}
\end{prooftree}
\end{gather*}
\caption{Natural deduction assumption rules}
\label{f-ND-ass}
\end{figure}
%
\begin{figure}
\centering \ebproofset{center=false}
\begin{gather*}
\begin{prooftree}
	\hypo{ [F] }
	\ellipsis{}{G}
	\infer1[$\impI$]{ F → G }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{F}
	\hypo{G}
	\infer2[$\conjI$]{ F ∧ G }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{ F(a) }
	\infer1[$\faI_a$]{ ∀x F(x) }
\end{prooftree}
\\[8pt]
\begin{prooftree}
	\hypo{ F }
	\infer1[$\disjI_0$]{ F ∨ G }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{ G }
	\infer1[$\disjI_1$]{ F ∨ G }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{ F(t) }
	\infer1[$\exI$]{ ∃ x F(x) }
\end{prooftree}
\end{gather*}
\caption{Natural deduction introduction rules}
\label{f-ND-intro}
\end{figure}
%
\begin{figure}
\centering \ebproofset{center=false}
\begin{gather*}
\begin{prooftree}
	\hypo{ ⊥ }
	\infer1[$\botE$]{ F }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{F ∧ G}
	\infer1[$\conjE_0$]{ F }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{F ∧ G}
	\infer1[$\conjE_1$]{ G }
\end{prooftree}
\qquad
\begin{prooftree}%[center=false]
	\hypo{ ∀x F(x) }
	\infer1[$\faE$]{ F(t) }
\end{prooftree}
\\[8pt]
\begin{prooftree}
	\hypo{ F → G }
	\hypo{ F }
	\infer2[$\impE$]{ G }
\end{prooftree}
\qquad
\begin{prooftree}
	\hypo{ F ∨ G }
	\hypo{ [F] }
	\ellipsis{}{H}
	\hypo{ [G] }
	\ellipsis{}{H}
	\infer3[$\disjE$]{ H }
\end{prooftree}
\qquad
\begin{prooftree}[center=false]
	\hypo{ ∃x F(x) }
	\hypo{ [F(a)] }
	\ellipsis{}{H}
	\infer2[$\exE_a$]{ H }
\end{prooftree}
\end{gather*}
\caption{Natural deduction elimination rules}
\label{f-ND-elim}
\end{figure}

\paragraph{Assumption.} There are two zero-premise rules for initiating formulas as \emph{assumptions}:
\[
  \begin{prooftree}
  	\axiom[\assumpo]{F}
  \end{prooftree}
  \qquad
  \begin{prooftree}
  	\axiom[\assumpd]{F}
  \end{prooftree}
\]
The only difference between the rules is their name. The fact that we have two, identical, rules for assumptions is because of their double role, either as \emph{open} assumptions or as assumptions which have been \emph{discharged} by another rule.
The two rules \( (\assumpo) \) and \( (\assumpd) \) represent this dichotomy: the conclusion of the rule \( (\assumpo) \) will be called an \emph{open} assumption, and conclusions of \( (\assumpd) \) as \emph{discharged}, or \emph{closed}, assumptions.
%As the assumption rule is the only zero-premise rule in natural deduction, mention of it will be suppressed.

\paragraph{Falsum.} The connective \( ⊥ \) has no introduction rule, but an elimination rule that permits the derivation of any formula from it.
\[
  \begin{prooftree}[center=false]
  	\hypo{ ⊥ }
  	\infer1[$\botE$]{ F }
  \end{prooftree}
\]


\paragraph{Conjunction.} This connective is associated one introduction rule and two elimination rules:
\[
  \begin{prooftree}
  	\hypo{F}
  	\hypo{G}
  	\infer2[$\conjI$]{ F ∧ G }
  \end{prooftree}
  \qquad
  \begin{prooftree}
  	\hypo{F ∧ G}
  	\infer1[$\conjE_0$]{ F }
  \end{prooftree}
  \qquad
  \begin{prooftree}
  	\hypo{F ∧ G}
  	\infer1[$\conjE_1$]{ G }
  \end{prooftree}
\]

\paragraph{Implication.} An introduction rule (discharging an assumption) and one elimination rule
\[
  \begin{prooftree}[center=false]
  	\hypo{ [F] }
  	\ellipsis{}{G}
  	\infer1[$\impI$]{ F → G }
  \end{prooftree}
  \qquad
  \begin{prooftree}[center=false]
  	\hypo{ F → G }
  	\hypo{ F }
  	\infer2[$\impE$]{ G }
  \end{prooftree}
\]
As explained above, the introduction rule allows the assumption \( F \) to be considered as discharged in the subderivation, indicated by the notation
\begin{prooftree*}
	\hypo{[F]}
	\ellipsis{}{}
\end{prooftree*}%
This information is not strictly part of the inference but is relevant for the notion of entailment in natural deduction, the relation of ‘being derivable from assumptions’.

\paragraph{Disjunction.} Two introduction rules and one elimination rule, the latter with discharged assumptions.
\[
  \begin{prooftree}[center=false]
  	\hypo{ F }
  	\infer1[$\disjI_0$]{ F ∨ G }
  \end{prooftree}
  \qquad
  \begin{prooftree}[center=false]
  	\hypo{ G }
  	\infer1[$\disjI_1$]{ F ∨ G }
  \end{prooftree}
  \qquad
  \begin{prooftree}[center=false]
  	\hypo{ F ∨ G }
  	\hypo{ [F] }
  	\ellipsis{}{H}
  	\hypo{ [G] }
  	\ellipsis{}{H}
  	\infer3[$\disjE$]{ H }
  \end{prooftree}
\]

\paragraph{Universal quantifier.} An introduction and elimination rule. 
The introduction rules are separated according to the variable being ‘discharged’. Application of the introduction rules are subject to the \emph{eigenvariable condition} below.
\[
  \begin{prooftree}%[center=false]
  	\hypo{ F(a) }
  	\infer1[$\faI_a$]{ ∀x F(x) }
  \end{prooftree}
  \qquad
  \begin{prooftree}%[center=false]
  	\hypo{ ∀x F(x) }
  	\infer1[$\faE$]{ F(t) }
  \end{prooftree}
\]
Recall that per convention~\ref{conv-subst}, in the introduction rule \( F(x) \) means \( F[x/a] \). In particular, the variable \( a \) never occurs in the conclusion of \( \faI_a \). In the elimination rule \( \faE \), \( ∀x F(x) \) and \( F(t) \) mean \( ∀x F[x/b] \) and \( F[t/b] \) for some (unspecified) variable \( b \).


%\begin{thing}[Eigenvariable condition for \( \faI \)]
%	The rule \( \faI_a \) is applicable only if \( a \) does not occur in any assumptions above this inference which is \emph{undischarged} after applying this rule.
%\end{thing}


\paragraph{Existential quantifier.} To the universal quantifier as  disjunction is to conjunction:
\[
  \begin{prooftree}[center=false]
  	\hypo{ F(t) }
  	\infer1[$\exI$]{ ∃ x F(x) }
  \end{prooftree}
  \qquad
  \begin{prooftree}[center=false]
  	\hypo{ ∃x F(x) }
  	\hypo{ [F(a)] }
  	\ellipsis{}{H}
  	\infer2[$\exE_a$]{ H }
  \end{prooftree}
\]
Applications of \( \exE_a \) are also constrained by restricting where an eigenvariable condition:

\begin{thing}[Eigenvariable condition]
	The rules \( \faI_a \) and \( \exE_a \) are applicable only if \( a \) does not occur in the formula \( H \) nor in any assumption above this inference which is \emph{undischarged} after applying this rule.
\end{thing}

\begin{example}
	The following is derivation in the above rules of
	\( ∃x ¬F→¬∀x F \). Notice that all assumptions are discharged (and that discharged assumptions are annotated by the rule instance that discharged them):
	\begin{prooftree*}
		\hypo{ [∃x ¬F]^\dag }
		\hypo{ [ ¬ F(a) ]^{\dag\dag} }
		\hypo{ [∀x F]^\ddag }
		\infer1[$\faE$]{ F(a) }
		\infer2[$\impE$]{ ⊥ }
		\infer2[$\exE_a^{\dag\dag}$]{ ⊥ }
		\infer1[$\impI^\ddag$]{ ¬∀x F }
		\infer1[$\impI^\dag$]{∃x ¬F→¬∀x F }
	\end{prooftree*}
	The derivation above is well-formed: for the single inference to which the eigenvariable condition applies, \( \exE_a \), the variable \( a \) does not occur in an undischarged assumption (except for the assumption \( ¬ F(a) \) which is discharged by this inference).
\end{example}
%
\begin{definition}[Natural deduction, \( \Ni \)]
	\emph{Natural deduction} is the calculus \( \Ni \) over formulas comprising the aforementioned rules.
	A \emph{deduction} is a finite derivation in \( \Ni \) which fulfills the eigenvariable condition.
%	A well-formed derivation in \( \Ni \), i.e., one that satisfies the eigenvariable condition, is called a \emph{deduction}.
\end{definition}
	
\begin{definition}[Entailment]
	The \emph{entailment relation} is a relation \( ⊢ \) between a finite set of formulas and a formula defined as \( Γ ⊢ F \) iff that there exists a deduction in \( \Ni \) with conclusion \( F \) such that every undischarged assumption of this derivation is an element of \( Γ \).
	
	A \emph{validity} of \( \Ni \) is any formula \( F \) such that \( ∅ ⊢ F \) holds; also written as \( ⊢ F \).
\end{definition}


As a direct consequence of the definition, I deduce
\begin{lemma}\label{nd-i-transitive}
	If\/ \( Γ ⊢ F \) and \( Δ ∪ \setof F ⊢ G \), then \( Γ ∪ Δ ⊢ G \)
\end{lemma}
%
As \( Δ ∪ \setof F ⊢ F \) for all \( Δ \) and \( F \), a special case of \cref{nd-i-transitive} is
\begin{lemma}
	\( Γ ⊢ F \) implies \( Γ ∪ Δ ⊢ F \) for all \( Δ \).
\end{lemma}

\begin{theorem}[Deduction]
%	If \( F \) is a sentence, then
	For all \( F \) and \( G \):
	\( Γ ∪ \setof F ⊢ G \) iff \( Γ ⊢ F → G \).
\end{theorem}

\begin{lemma}\label{nd-i-fa}
	If\/ \( Γ \) is a set of sentences and \( F(a) \) any formula, then 
	\( Γ ⊢ F \) iff \( Γ ⊢ ∀x F(x) \).
\end{lemma}


\begin{exercise}
	Prove \ref{nd-i-transitive}--\ref{nd-i-fa}.
\end{exercise}

%
\begin{exercise}
	Express the correctness criterion for \( \Ni \) as a property of paths.
	That is, specify the correctness condition \( \Coll C \) as a set of sequences of formulas and rules such that a derivation \( D \) is a deduction iff every path through \( D \) is contained in \( \Coll C \).
\end{exercise}

The set of validities of \( \Ni \) determines a logic, known as intuitionistic logic.
%Not classical predicate logic, but intuitionistic logic.

\begin{definition}[Intuitionistic logic]
%	\emph{Intuitionistic logic} is identified with the natural deduction calculus \( \Ni \). 
	\( \IL \) is the set of validities of \( \Ni \).
	I write \( \IL ⊢ F \) iff \( F ∈ \IL \), iff \( ∅ ⊢ F \) holds (in \( \Ni \)).
\end{definition}

% --------------------------------------
\section{Classical logic}
% --------------------------------------

In contrast to intuitionistic logic, classical logic is defined via semantics, specifically, Tarskian semantics.
%Let \( \Lang L \) be a first-order language.
I will not recap the definition here;
the reader can consult, for example, \citetalias[ch.~4]{LogThe}.

Classical logic can also be captured syntactically.

\begin{definition}[Classical natural deduction, \( \Nc \)]
	The calculus \( \Nc \) is the extension of \( \Ni \) by the rule \( \RAA \):
	\[
		\begin{prooftree}
			\hypo{ [¬ F] }
			\ellipsis{}{ ⊥ }
			\infer1[$\RAA$]{ F }
		\end{prooftree}
	\]
	with the same eigenvariable conditions applying to deductions.
	
	The entailment relation for \( \Nc \) is denoted \( ⊢_\CL \).
	That is, \( Γ ⊢_\CL F \) express the existence of a deduction according to \( \Nc \) with conclusion \( F \) in which all undischarged assumptions are elements of \( Γ \).
\end{definition}

\( \RAA \) stands for \emph{reductio ad absurdum}.
To avoid potential confusion, I use \( ⊢_\IL \) for the entailment 

\begin{theorem}
	The following are equivalent.\label{nd-c-i}
	\begin{enumerate}
		\item \( Γ ⊢_\CL F \).
		\item \( Γ ∪ \setof{ ¬ F} ⊢_\CL ⊥ \).
		\item \( Γ ∪ \setof{ ¬ ¬ G → G }[G ∈ Δ] ⊢_\IL F \) for some set \( Δ \).
		\item \( Γ ∪ \setof{ G ∨ ¬ G }[G ∈ Δ] ⊢_\IL F \) for some set \( Δ \).
	\end{enumerate}
\end{theorem}

\begin{exercise}
	Prove \cref{nd-c-i}.
\end{exercise}

%In this course we will not need to assume


